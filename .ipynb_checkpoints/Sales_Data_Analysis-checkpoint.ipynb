{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b90dc6b-785a-462c-bf1c-1d8a661689ca",
   "metadata": {},
   "source": [
    "# Sales Data Analysis and Visualization Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857283ac-6d0f-44ce-8b9f-e11de786f2e5",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Data Loading and Inspection](#Data-Loading-and-Inspection)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "4. [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis-(EDA))\n",
    "    - [Sales Over Time](#Sales-Over-Time)\n",
    "    - [Sales By Product](#Sales-By-Product)\n",
    "    - [Sales By Region](#Sales-By-Region)\n",
    "6. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2208b-91f6-4a0d-8bda-05fb7c7e38ac",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1570d88-84b6-4db6-869b-fc858d3d44a8",
   "metadata": {},
   "source": [
    "In today's data-driven world, businesses rely heavily on data analysis to make informed decisions and drive growth. The objectives of this project are to inspect, clean, and perform exploratory data analysis (EDA) on sales data in order to gain insights and uncover key trends to motivate business success. The dataset contains information on sales transactions, including date, product, region, quantity, price, and customer information.\n",
    "\n",
    "We will use Pandas for data processing, and Matplotlib + Seaborn for data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7aaf41-03b3-4c14-815c-61a943162b7c",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae63de68-e7f8-412e-b984-1afef106c5d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14212/3017815687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import libraries for data processing and visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuncFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import libraries for data processing and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter, ScalarFormatter\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c6801-ecbb-4c73-aa14-73f60ae943b4",
   "metadata": {},
   "source": [
    "First, we load the data and extract some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b245-913e-4d66-9295-70e8f68c737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('sales_data_sample.csv', index_col='ORDERNUMBER')\n",
    "\n",
    "# First 5 rows\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3798f-23ee-4d74-9623-c4f4990df51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs the \"Big 5\" as well as count, mean, and standard deviation\n",
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb276c-95bc-4b0a-8183-f1c66e45e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = sales_data.isnull().sum().astype(str) + ' null'\n",
    "non_null_counts = sales_data.notnull().sum().astype(str) + ' non-null'\n",
    "dtypes = sales_data.dtypes\n",
    "\n",
    "# Contains number of null and non-null entries as well as the type of the entry for each column\n",
    "sales_info = pd.DataFrame({'Non-Null Count': non_null_counts, 'Null Count': null_counts, 'dtype': dtypes,})\n",
    "print(sales_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c935d04e-9101-478a-8326-4fcb2763996f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297bf39f-7caa-41d9-a070-af226b7df014",
   "metadata": {},
   "source": [
    "From above, we see that ADDRESSLINE2, STATE, and TERRITORY columns have null rows. We would lose way too much valuable information if we dropped these rows. Let's fill in the missing values instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceea582-823d-45c0-bb48-69312e159846",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.fillna({'ADDRESSLINE2': 'No Address Line'}, inplace=True)\n",
    "sales_data.fillna({'STATE': 'No State'}, inplace=True)\n",
    "sales_data.fillna({'TERRITORY':'No Territory'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375c48e-3b3b-4a05-9f50-8bd4ee9af4a8",
   "metadata": {},
   "source": [
    "Now let's check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8306b-93d1-4111-83b9-6cb076cfad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = sales_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows is {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe271e96-302c-41db-a1b2-2f5b6a5218d9",
   "metadata": {},
   "source": [
    "Next let's convert the ORDERDATE datatype for additional date-related features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46696e-b673-4ae1-b8d8-6795d4e60027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['ORDERDATE'] = pd.to_datetime(sales_data['ORDERDATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093dc0c-055b-4195-ad54-f09a98c190ac",
   "metadata": {},
   "source": [
    "Finally, let's visualize outliers using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9752ab8-e1cb-458c-8c29-517ddea7b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers for Sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=sales_data[['SALES']], color=\"green\")\n",
    "plt.title('Boxplot of Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbd65e-518e-41a2-9612-0e1c98879d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers for Quantity Ordered and Price Each\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=sales_data[['QUANTITYORDERED', 'PRICEEACH']])\n",
    "plt.title('Boxplot of Quantity Ordered and Price Each')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9a8b3-88ea-4273-8051-3b2c95c87715",
   "metadata": {},
   "source": [
    "All outliers in this dataset seem to be true outliers (i.e. are not a result of measurement errors, data entry errors, or poor sampling). For this reason, we will not remove any outliers.\n",
    "\n",
    "From just the box plots we can extract some information about the shape of the distributions of each of these variates. For example, QUANTITYORDERED is fairly symmetric, PRICEEACH has a negative skew (longer left tail), and SALES has a positive skew (longer right tail). We can makes these conclusions by observing the location of the median line relative to the IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796b119-4e16-45f5-bf8a-38e167846260",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80022e-0fd1-493a-a1f5-85e122559bb0",
   "metadata": {},
   "source": [
    "## Sales Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec79cb-4fd2-4a7b-a742-2f601fe8a504",
   "metadata": {},
   "source": [
    "First we look at the sales over the course of the entire time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40842a30-2988-466c-b059-b8d30c520243",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14212/2839806171.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msales_over_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ORDERDATE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SALES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msales_over_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Sales Over Time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Total Sales (Millions)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales_data' is not defined"
     ]
    }
   ],
   "source": [
    "sales_over_time = sales_data.resample('ME',on='ORDERDATE')[['SALES']].sum()\n",
    "sales_over_time.plot(title=\"Sales Over Time\", xlabel=\"Date\", ylabel=\"Total Sales (Millions)\", figsize=(14, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a5d5b-9094-435b-aaf4-7883cce1146f",
   "metadata": {},
   "source": [
    "Notice how there are spikes in sales from September-December. Let's plot information for monthly sales to better visualize these seasonal trends. It would be insightful to plot average monthly sales, however there is incomplete data from 2005. Adding the sales from the available months of 2005 would skew the data for said months. To avoid this, let's only consider data from 2003 and 2004. Furthermore, we will also color the plot by quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a3855-67b9-46c2-b97e-2e2b5b372975",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = sales_data[sales_data['YEAR_ID'] < 2005] # data from 2003 and 2004\n",
    "total_monthly_sales = filtered_data.groupby(['YEAR_ID', 'MONTH_ID', 'QTR_ID'])['SALES'].sum().reset_index()\n",
    "average_monthly_sales = total_monthly_sales.groupby(['MONTH_ID', 'QTR_ID'])['SALES'].mean().reset_index()\n",
    "\n",
    "quarter_labels = {\n",
    "    1: 'Q1',\n",
    "    2: 'Q2',\n",
    "    3: 'Q3',\n",
    "    4: 'Q4'\n",
    "}\n",
    "\n",
    "# We map the quarter ids to Q1, Q2, Q3, and Q4 for readability in the legend\n",
    "average_monthly_sales['QTR_ID'] = average_monthly_sales['QTR_ID'].map(quarter_labels)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='MONTH_ID', y='SALES', data=average_monthly_sales, palette='light:purple', hue='QTR_ID')\n",
    "\n",
    "plt.title('Average Monthly Sales (2003-2004)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Sales (Millions)')\n",
    "plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.legend(title=\"Quarter\", loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
